\documentclass{spbau-diploma}

\begin{document}

\filltitle{ru}{
    chair              = {Кафедра математических и информационных технологий},
    title              = {Управляемая генерация текста с использованием механизма внимания},
    type               = {bachelor},
    position           = {студента},
    group              = 402,
    author             = {Беляев Станислав Валерьевич},
    supervisorPosition = {к.\,ф.-м.\,н., исследователь},
    supervisor         = {Николенко С.\,И.},
    reviewerPosition   = {исследователь},
    reviewer           = {Шпильман А.\,А.},
    chairHeadPosition  = {д.\,ф.-м.\,н., профессор},
    chairHead          = {Омельченко А.\,В.},
}

\filltitle{en}{
    chair              = {Department of Mathematics and Information Technology},
    title              = {Controllable text generation using Attention mechanism},
    author             = {Stanislav Belyaev},
    supervisorPosition = {researcher},
    supervisor         = {Sergey Nikolenko},
    reviewerPosition   = {researcher},
    reviewer           = {Alexey Shpilman},
    chairHeadPosition  = {professor},
    chairHead          = {Alexander Omelchenko},
}

\maketitle
\tableofcontents

\section{Введение}
В этой главе представлены краткое описание предметной области, дано описание
проблемы и представлены смежные работы.

\subsection{Обзор}
Современные алгоритмы машинного обучения показывают многообещающие результаты
в области генеративных моделей. Нейронным сетям удается эффективно обобщать 
зависимости для данных, имеющих представление в виде непрерывного многомерного
вектора. В частности, последние результаты в visual domain (картинки, видео) 
способны генерировать очень правдоподобные примеры, которые даже человеку бывает
трудно отличить на глаз от настоящих (рис.~\ref{gan_sota}).

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{images/gan_sota.jpeg}
\caption{2 года прогресса на датасете ImageNet-128}
\label{gan_sota}
\end{figure}

Тем не менее, такого же результата не удается добиться при генерации дискретных 
значений (как, например, текста). Почему так происходит? Ответ кроется в природе 
генерируемых значений. Дело в том, что над непрерывными значениями гораздо проще 
определить всевозможные операции и преобразования, после чего эффективно 
оптимизировать функцию ошибки с помощью стохастического градиентного спуска. В 
дискретном же пространстве некоторые операции теряют свойство дифференцирования, 
из-за чего посчитать аналитически или программно производную по какой-либо 
переменной становится невозможным. Чтобы избежать этого, применяется ряд приемов, 
описанные, например, в Goodfellow et al.(2017)~\cite{1701.00160}. Помимо этого, 
сама структура текста предполагает некоторые сложности, связанные с long-term 
зависимостями, омонимией и контекстом (рис.~\ref{pics_vs_text}).

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{images/pics_vs_text.png}
\caption{Сравнение картинок и текста для задач генерации}
\label{pics_vs_text}
\end{figure}

В общем и целом, задача генерации текста остается нерешенной, или, по крайней
мере, решенной недостаточно хорошо, чтобы стать полезным инструментом для 
помощи человеку в повседневных задачах.

В данной работе проанализированные подходы к генерации дискретных значений с
помощью подходов из глубокого обучения. Обозначенные основные проблемы и 
предложены возможные пути их решения.

\subsection{Постановка задачи}
\newcommand{\Xtrain}{X_{\texttt{train}}}
\newcommand{\pdata}{p_{\texttt{data}}}
\newcommand{\pmodel}{p_{\texttt{model}}}
Определимся с постановкой задачи. Любая генеративная задача может быть 
сформулирована следующим образом: необходимо реализовать алгоритм, принимающий 
на вход обучающее множество примеров $\Xtrain$ из генеральной совокупности $X$ 
распределенных по некому сложному распределению $\pdata$ и строящий $\pmodel$, 
приближающее реальное распределение данных. Алгоритм может строить $\pmodel$ как 
конструктивно, приближая $\pdata$, заранее знакомым простым распределением 
(рис.~\ref{density_estimation}), так и неявно, ограничиваясь 
только способностью эффективно (по памяти и времени исполнения) сэмплировать 
(=генерировать) новые примеры (рис.~\ref{density_samples}). Некоторые модели 
способны делать и то и другое, но, обычно, этого не требуется.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{images/density_estimation.png}
\caption{Приближение $\pdata$ одномерной гаусианной}
\label{density_estimation}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{images/density_samples.png}
\caption{Приближение $\pdata$ через сэмплирование новых примеров}
\label{density_samples}
\end{figure}

В нашем случае, мы будем фокусироваться на проблеме генерации текстовых данных.
Обычно, они представлены в "сыром виде", то есть последовательностями
букв из конечного алфавита. Мы будем фокусироваться на английском языке, 
ввиду его распространенности, и, следовательно, простоты получения данных, хотя 
получившиеся модели не в коей мере не будут привязаны к конкретному языку и 
, более того, не будут привязаны к тексту вообще: мы можем считать данные 
последовательностями дискретных значений, о которых легче думать как о тексте.

Необходимо будет также расширить постановку классической задачи следующим 
образом. Помимо способности получать правдоподобные примеры, мы также хотим
контролировать процесс генерации, параметризовав его неким свойством, 
присущим текстовой единице. Например, эмоциональная окраска или одна из $20$ 
предложенных тем. Такая постановка более подходит для практических нужд: 
обычно, текст обладает неким набором свойств, а генерация новых сэмплов 
"в вакууме" никому не интересна. Помимо этого, стоит учесть, что не все данные
могут иметь полную разметку свойств, поэтому модель должна уметь это учитывать.
Это также позволит дешево дополнить датасет данными из той же области: обычно, 
"сырой" текст без разметки прост и дешев в получении.

Особенно близко мы посмотрим на классы генеративных моделей \textbf{VAE} и 
$\textbf{GAN}$, показывающие наилучшие результаты на данный момент. Нам будет
интересно расширить существующие подходы так, чтобы избежать больших недостатков
обеих моделей, правильно используя их сильные стороны. Самый большой недостаток
обеих подходов - ограничение в длине генерируемых примеров ($15-20$ слов). Нам
будет интересно попытаться преодолеть это ограничение (или хотя бы увеличить 
вдвое), поддерживая одновременно связность, правдоподобность и разнообразие 
генерации. Такие ограничения созданы искусственно для хороших результатов и 
совершенно не подходят для конкретных применений.

\subsection{Работы на предложенную тему}
В последнее время, интерес исследователей к теме генерации текста значительно
возрос. Посмотрим на основные работы в данной теме.

Существует несколько подходов к генерации текста как последовательности
дискретных значений. Прорывной является работа 
Sutskever et al. (2014)~\cite{1409.3215}, в которой реализована модель перевода 
с английского языка на французский используя 
\textbf{long short term memory (LSTM)} рекуррентные сети:
одну к качестве энкодера (запоминающего входную информацию) и одну в качестве 
декодера (генератора). Результаты получились сравнимы с методами перевода,
основанными на статистике, хотя модель и не требовала множества ручной работы и
учета особенностей языка: нейронные сети сами обобщили зависимости между 
корпусами параллельных текстов. Успех также можно объяснить выбором модели для
последовательностей, LSTM, которая специально создавалась для борьбы с проблемой
"длинных связей" в предложении и проблемой затухающих градиентов. Ввиду своей
простоты, \textbf{Seq2Seq} модель получилась расширяемой и модифицируемой. В 
частности, стали популярные вариации с использованием механизма внимания и 
техники \textbf{Beam search} при генерации~\cite{blog:seq2seq}. Хоть данная 
работа и не относится напрямую к задаче, практики и подходы отсюда используются
повсеместно.

Для генерации текста, лучшие результаты показывают~\cite{text_vae}, 
\cite{text_cvae}, \cite{leakgan}. Принцип их работы, преимущества и недостатки, 
будут разобраны в Главе 2. Данные работы имеют схожие по формулировкам задачи, 
но, к сожалению, разные данные и метрики.

\subsection{Применение}
Постановка задачи частично диктуется конкретными задачами из индустрии. 
Например, мы хотим написать универсальный генератор условий задачек по заданным 
темам для MOOC курса, возможно облегчив работу автором и составителям задачек.
Формальная постановка эквивалента вышеописанной: входные данные - текст,
присутствует частичная разметка (просто условий задачек много, а размеченных 
мало), слишком коротких условий мы также не хотим.

Полученная модель в дальнейшем может быть использована для генерации любых
дискретных последовательностей. Например, одно из представлений молекулярных 
структур, \textbf{SMILES}, подразумевает строчку из $26$ уникальных символов 
(Рис.~\ref{smiles}).

\begin{figure}[h]
\centering
\includegraphics{images/smiles.png}
\caption{\textbf{SMILES} представление молекул}
\label{smiles}
\end{figure}

Набор таких строчек может стать входными данными для генеративных моделей, 
однако наиболее частой задачей в данной области является условная генерация (мы
оптимизирует какое-либо свойство молекулярной структуры, например: валентность, 
содержание этанола, и.т.д). Опять же, разметка может присутствовать не на всех
молекулярных структурах.

\section{Обзор существующих решений}
В этой главе будут описаны существующие подходы к задаче генерации, недостатки
и достоинства существующих генеративных моделей.

\subsection{Таксономия генеративных моделей}
В последнее время, все больше задач из машинного обучения успешно решаются с 
помощью подходов, основанных на нейронных сетях. В том числе, успешно удается
решать задачи из области обработки естественного языка, такие как суммаризация
текста, определение эмоциональной окраски и машинный перевод. Прорывной работой,
сместившей фокус внимания в области обработки естественного языка на нейронные
сети можно считать работу Mikolov et al.~\cite{rnnlm}, которая успешно решала
задачу построения языковой модели с помощью рекуррентных нейронных сетей, без
необходимости вручную или с помощью статистики улавливать закономерности и 
зависимости между словами в языке.

Основные задачи в области обработки естественного языка, включая генерацию 
текста, включают в себя некий набор входных строк-последовательностей, 
использующихся для обучения. Предшествующие методы для генерации были либо 
основаны на правилах, либо на хорошо изученных вероятностных моделях, таких как
$n$-граммных или линейных~\cite{statmodel1}, \cite{statmodel2}. Такие подходы,
несмотря на свою изученность и интерпретируемость, нуждаются в огромном 
количестве "ручной работы" - в случае подходах, основанных на правилах - или 
просто имеют ограничение в качестве и точности работы, поэтому не могут 
эффективно использовать большие объемы данных 
(Jozefowicz et al.~\cite{1602.02410}). С другой стороны, ставшие популярными в 
последние годы нейронные архитектуры, несмотря на хорошие результаты, плохо 
изучены и не всегда хорошо интерпретируемы. Несмотря на недостатки, в этой 
работе также будут использоваться нейронные модели с end2end архитектурами (то 
есть работающие напрямую с "сырыми" строковыми представлениями как на вход так 
и на выход), в основном из-за своей эффективности и расширяемости.
Рисунок~\ref{approaches} иллюстрирует компромисс в сравнении работы двух 
подходов.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{images/approaches.png}
\caption{Сильные и слабые стороны подходов в обработке естественного языка}
\label{approaches}
\end{figure}

Процесс обучения нейронной архитектуры тесно связан с методом приближения 
истинного распределения $\pdata$. Большинство из них работают по 
\textbf{принципу максимального правдоподобия} (Рис.~\ref{mll_density}). Не 
все из них используют этот принцип напрямую, но могут быть переделаны или
переопределены так, чтобы так или иначе использовать его~\cite{1701.00160}.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{images/mll_density.png}
\caption{Процесс обучения через принцип максимального правдоподобия}
\label{mll_density}
\end{figure}

Нейронная архитектура моделирует распределение $\pmodel$, приближающее истинное
$\pdata$ и параметризованное набором весом $\theta$. Сам принцип максимально 
правдоподобия есть ни что иное как выбор параметров модели, максимизирующих
правдоподобие тренировочных данных по формуле \ref{maximum_likelihood}. Легче
всего это производится в $\log$-пространстве, так как мы заменяем произведение 
по тренировочным примерам на сумму (Формула~\ref{log_maximum_likelihood}). Сумма
упрощает численную реализацию подсчетов и упрощает подсчет градиента, а также 
позволяет избежать проблем с переполнением чисел с плавающей точкой. 

\begin{equation}
\label{maximum_likelihood}
\theta^* = \argmax_{\theta} \prod^{n}_{i=1}{\pmodel(x^{(i)}; \theta)}
\end{equation}

\begin{equation}
\label{log_maximum_likelihood}
\begin{split}
\theta^* = \argmax_{\theta} \prod^{n}_{i=1}{\pmodel(x^{(i)}; \theta)} \\
= \argmax_{\theta} \log \prod^{n}_{i=1}{\pmodel(x^{(i)}; \theta)} \\
= \argmax_{\theta} \sum\limits^{n}_{i=1}{\log \pmodel(x^{(i)}; \theta)}
\end{split}
\end{equation}

Максимизация правдоподобия может быть рассмотрена как эквивалентная минимизации
дивергеции Кульбака-Лейблера (\cite{wiki:kldiv}), которая задает некое 
расстояние между распределениями. Точнее, если бы нам удалось точно приблизить 
$\pdata$, то оно бы принадлежало семейству распределений $\pmodel(x; \theta)$. 
На практике, мы не имеем доступа к $\pdata$, а лишь знаем о $n$ точках из 
тренировочной выборки, которые мы используем чтобы задать $\hat 
p_{\texttt{data}}$ - эмпирическое распределение, аппроксимирующее $\pdata$. 
Минимизация дивергеции Кульбака-Лейблера между $\hat p_{\texttt{data}}$ и 
$\pmodel$ в точности эквивалентна максимизации правдоподобия
(Формула~\ref{kl_maximum_likelihood}).

\begin{equation}
\label{kl_maximum_likelihood}
\theta^* = \argmin_{\theta} D_{KL}(\hat p_{\texttt{data}}(x) || \pmodel(x; \theta))
\end{equation}

Если мы сузим внимание на глубокие нейронные архитектуры, основанные на 
вариациях метода максимизации правдоподобия, то можем ввести некую таксономию 
на разнообразие генеративных моделей в зависимости от того, как именно 
приближается исходное распределение (Рис.~\ref{gen_taxonomy2}). Каждый лист в
дереве на рисунке соответствует конкретному классу моделей, имеющему свои 
достоинства и недостатки. Нас не будут интересовать модели, основанные на 
марковских цепях, так как они имеют некоторые проблемы с стоимостью получения
сэмпла и корреляцией между сэмплами~\cite{vetrovgan}. Далее, мы 
последовательно рассмотрим модели с возможностью явно выразить распределение,
модели с аппроксимаций распределения и неявные вероятностные модели. Более 
точно, нас будут интересовать вариации этих подходов для задач генерации текста:
\textbf{RNN}, \textbf{VAE} и \textbf{GAN}.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{images/gen_taxonomy2.png}
\caption{Таксономия генеративных моделей}
\label{gen_taxonomy2}
\end{figure}

\subsection{RNN}
Рекуррентные нейронные сети используют принцип максимального правдоподобия 
напрямую, явно моделируя распределение $\pmodel$, приближающее $\pdata$. 

\subsubsection{Обучение}
На вход для обучения сети поступает набор из последовательностей 
$x = (x_1, \cdots, x_{|x|})$. $x_i$ - числовые представление слов из словаря,
фиксированного размера (в частности, слова, не найденные ), закодированные 
после токенизации \cite{wiki:token} сырой входной последовательности. Стоит
также отметить, что получившиеся слова не всегда соответствуют словам в 
привычном понимании (из естественного языка): они также могут быть любым другим
однозначным разбиением последовательности из символов - например, кусками из BPE
разбиения или вовсе обычными одиночными символам~\cite{1508.07909}, 
\cite{charnn}. Мы хотим
смоделировать совместную вероятность слов по формуле \ref{rnn_density}, что
в свою очередь эквивалентно формуле \ref{log_rnn_density} при переходе в 
$\log$-пространство.

\begin{equation}
\label{rnn_density}
p(x) = \prod^{|x|}_{i=1}{p(x_i | p_{<i})}
\end{equation}

\begin{equation}
\label{log_rnn_density}
\log p(x) = \sum\limits^{|x|}_{i=1}{\log p(x_i | p_{<i})}
\end{equation}

Архитектура RNN представлена на рисунке $\ref{rnn_unrolled}$. RNN - это 
последовательность из $|x|$ шагов нелинейных преобразований, принимающих 
очередную часть $x_i$ и скрытое представление $h_{i-1}$ c прошлого шага. Так как
изначально $x_i$ находятся в дискретном поле, перед скармливанию сети $x_i$ 
обычное векторизуют (переводят в непрерывное пространство). Для векторизации 
могут использоваться как обычное one-hot представление~\cite{onehot}, имеющее
смысл лишь при маленьком размере словаря, так более продвинутые "эмбеддинги" с 
семантической нагрузкой~\cite{word2vec}, \cite{glove}, \cite{elmo}. 
Преобразования $A$, параметризованные неким набором весом, сохраняют 
непрерывность и возможность посчитать градиент, а сам тип преобразования 
зависит от вида рекуррентной сети. Обычно используются популярные в последнее 
время и наиболее удачны архитектурно, \textbf{GRU}~\cite{1412.3555} и 
\textbf{LSTM}~\cite{lstm}, эффективно борящиеся с проблемой затухающих 
градиентов на длинных последовательностях.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{images/rnn_unrolled.png}
\caption{Схема работы рекуррентной нейронной сети}
\label{rnn_unrolled}
\end{figure}

Как считается $p(x_i|x_{<i})$ на очередном шаге RNN? Для этого используется 
очередное скрытое представление $h_i$. Например, мы можем применить полносвязный
слой~\cite{cnn}, переводящий $h_i$ в вектор $\mathbb{R}^{|V|}$, далее софтмакс
активация (\cite{wiki:softmax}), после которой мы фактически получаем 
распределение на вероятность следующего слова. Такое распределение можно 
противопоставить "истинному распределению", то есть onehot представлению нужного
символа, который известен в процессе обучения. Далее, мы можем выразить некое 
расстояние между распределениями, например, кросс-энтропия или дивергенцию 
Кульбака-Лейблера (их минимизация эквивалентна друг-другу). Итоговая ошибка - 
сумма ошибок на каждом шаге. Оптимизация происходит, обыкновенно, какой-либо 
вариацией стохастического градиентного спуска~\cite{optimizers} с обрезанием 
значений вектора градиента~\cite{gradient_clipping}.

\subsubsection{Генерация}
Теперь опишем подробно, как происходит генерация. Здесь и далее мы будем 
подразумевать генерацию случайных сэмплов без предусловия, а механизмы 
расширения для условной генерации будут описаны в следующей главе.

\newcommand{\bos}{\langle bos \rangle}
\newcommand{\sos}{\langle sos \rangle}
\newcommand{\eos}{\langle eos \rangle}
\newcommand{\unk}{\langle unk \rangle}
\newcommand{\pad}{\langle pad \rangle}
Обычно, полагается, что любой $x$ из данных для обучения - цельный, законченный 
отрывок текста из пары предложений, обрамленный с начала и конца соответственно 
условными словам $\bos/\sos$ и $\eos$ - символами начали и конца (begin of 
sequence, start of sequence, end of sequence). Для того, чтобы начать генерацию, 
мы подаем нашей RNN-ки на вход символ начала, а заканчиваем процесс, когда 
встретили символ конца (или достигли наперед заданного ограничения в 
максимальную длину сэмпла).

Как мы уже выяснили, RNN задает явное распределение $p(x_i|x_{<i})$ на очередном
шаге генерации. Самый очевидный и не совсем удачный способ - просэмплировать
очередной $x_i$ и двинуться дальше. Еще более плохой путь - взять 
$\argmax p(x_i|x_{<i})$ (несложно понять, что так мы всегда будем 
генерировать ровно один уникальный пример). О дихотомии этих двух крайностей и 
о более удачных подходах будет описано далее в главе "Решение". В общем же 
случае, процесс генерации, это хождение по дереву возможных вариантов
(Рис.~\ref{beam_search}). Нас будут интересовать пути с наибольшей совместной 
вероятностью слов. Несложно понять, что задача поиска таких путей NP-трудна и 
без перебора эффективно решить ее не получится. Также стоит отметить, что в 
идеале нам надо искать сразу $k$ наиболее правдоподобных примеров для повышения
разнообразия генеративной модели.

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{images/beam_search.png}
\caption{Процесс генерации в виде хождения по дереву}
\label{beam_search}
\end{figure}

\subsubsection{Преимущества и недостатки}
RNN - базовая модель, так или иначе использующаяся во всех подходах к генерации
строчек. Она обладает целым набором преимуществ, но и сильных недостатков, не
позволяющих использовать ее для нашей задачи.

К достоинствам можно отнести:
\begin{itemize}
    \item Эффективное и простое обучение: одна ошибка, один градиент, целый 
    набор приемов по оптимизации.
    \item Расширяемая и простая реализация. RNN - простая модель, поэтому она
    часть берется за основу и расширяется в сторону увеличения скорости 
    тренировки, предотвращения переобучения, повышения интерпретируемости 
    глубины сетки. К известным методам~\cite{bengio_rnn} можно отнести: 
    multi-layer rnn, bidirectional rnn~\cite{bidir_rnn}, 
    dropout~\cite{wiki:dropout}, scheduled sampling~\cite{1506.03099},
    attention~\cite{attention_rnn}, ensembling~\cite{wiki:ensebling},
    hierachy~\cite{1609.01704}, sru~\cite{1709.02755} и некоторые другие.
    \item Эффективное сэмплирование. Стоимость получения сэмпла низкая, возможно
    оценить совместную вероятность для подсчета метрик (См.~\ref{perplexity}),
    а также расширить алгоритм генерации эвристиками и регуляризацией.
\end{itemize}

К недостаткам относятся:
\begin{itemize}
    \item Небольшая эффективность по метрикам и быстрая потеря связности 
    начала с концом. Bengio~\cite{bengio_rnn}, к примеру, связывает это с 
    отсутствием изначального представления генерируемого сэмлпа. Мы 
    начинаем генерацию из пустоты, на ходу, слово за словом пытаясь создавать
    правдоподобный экземпляр, что приводит к плохой связности (coherence) при
    генерации.
    \item RNN работает только в условиях полной разметки данных. Если же данные
    размечены плохо или на части данных отсутствует разметка вовсе, то учесть
    это в стандартной рекуррентной нейронной сети - нетривиальная задача.
    \item Управляемая генерация. Как задать начальные условия для генерации в 
    RNN? Можно конкатенировать параметры условия с входом 
    $x_i$ на каждом шаге генерации (out-of-band) или добавить свойства текста
    в сам текст в качестве префикса и суффикса, тогда можно начинать генерацию
    с нужного префикса (in-band). Оба эти подхода работают плохо даже на самых
    простых данных~\cite{rnn_meta}.
\end{itemize}

В общем и целом, RNN - хорошая базовая модель, недостатки которой пытаются 
преодолеть в других подходах.

\subsection{VAE}
Одна из популярных архитектур генеративных моделей - вариационные автоэнкодеры
(variational autoencoder, VAE). VAE основаны на вариационном продолжении 
автоэнкодеров, выучивающих латентное представление обучающих примеров.

\subsubsection{Обзор}
Архитектура автоэнкодеров представляет из себя 2 нейронные сетки - энкодер, 
переводящий сэмпл $x,~x \in \mathbb{R}^n$ в латентное представление $z,~z \in \mathbb{R}^m, m \ll n$, и декоре, моделирующий обратное преобразование. 
Ошибка сети есть ошибка восстановления на батчах из тренировочного набора. AE -
модель обучения без учителя, позволяющая сжать входные данные до пространства
меньшего размера, получив универсальный трансформатор $x$ в латентное 
представление $z$. $z$ может быть в дальнейшем использоваться в том числе и для
обучения с учителем.

Декодер в архитектуре АЕ фактически представляет из себя этакий генератор $x$
по заданному латентному представлению. Однако, полноценно использовать его для
задач генерации не получится. В обычном AE мы не моделируем $\pmodel$, 
приближая $\pdata$, поэтому и непонятно откуда сэмплировать $z$ чтобы 
генерировать новые примеры. 

VAE решает эту проблему. Пусть $x$ как и $z$ - случайные величины, имеющие
распределения $\pdata$ и $p(z) = N(0, I)$. Выбор гаусианы в качестве априорного
не случаем - это простое распределение, с которым гораздо легче решать задачу
оптимизации. Скажем, теперь, что энкодер $q(z|x)$ будет аппроксимировать сложное 
апостериорное распределение $p(z|x)$ и также будет делать это многомерной
гаусианой, сразу предсказывая среднее и дисперсию по каждой компоненте. Декодер
же будет отвечать за $p_{\theta}(x|z)$ (Рис.~\ref{vae_terms}). 

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{images/vae_terms.png}
\caption{Архитектура VAE}
\label{vae_terms}
\end{figure}

Попытаемся выписать логарифм правдоподобия на тренировочном наборе. Известный 
результат - нижняя вариационная оценка ELBO~\cite{vae} представлена на 
Формуле~\ref{elbo}. Фактически, мы зажимаем правдоподобие снизу формулой которую
можно оптимизировать напрямую по весам энкодера и декодера. Второй терм - 
дивергенция Кульбака-Лейблера между двумя гаусианами - имеет аналитическое 
решение и может быть выражена с помощью дифференцируемых преобразований. Тонкий
момент - пробрасывание градиента через сэмплирование из апостериорного 
распределения $q$. Его можно избежать если заранее просэмплировать значения из
белого шума, а потом параметризовать его предсказанными матожиданием и 
дисперсией (Рис.~\ref{vae_terms}).

\begin{equation}
\label{elbo}
\log p(x) \geqslant \mathbb{E}_z{[\log p_{\theta}(x|z)]} - D_{KL}{(q(z|x) || p(z))}
\end{equation}

Итак, ошибка у VAE - сумма ошибки восстановления по аналогии с AE и kl-терм, 
выражающий расстояние между двумя гаусианами - аппроксимацией апостериорного и
априорным распределениями. В данном случае kl-терм можно интерепретировать как 
регуляризацию на форму латентного пространства.

Итак, теперь мы получаем возможность сэмплировать из $\pmodel$, 
аппроксимирующее $\pdata$. Возьмем $z \sim p(z)$ и загоним в декодер 
$p_{\theta}{(x|z)}$. Получили эффективный, низкий по стоимости и легкий в 
обучении генератор сэмплов, то есть генеративную модель.

\subsubsection{Дискретные данные}
Впервые, успешно применить VAE для генерации дискретных значений удалось 
Bowman et al.~\cite{text_vae}. Декодер и декодер представляют из себя 
рекуррентные нейронные сети LSTM, энкодер с последнего слоя с последнего 
скрытого представления генерирует матожидание и дисперсию для апостериорного
распределения, а к декодеру на каждый входной $x$ добавляется скрытый вектор
$z$. Схематически архитектура изображена на Рисунке~\ref{text_vae}.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{images/text_vae.png}
\caption{Архитектура TextVAE}
\label{text_vae}
\end{figure}

Несмотря на простоту подхода, такой вариант реализации не будет работать 
правильно. Дело в том, что декодер начинает учитсья намного быстрее энкодера,
поэтому сеть игнорирует ошибку с kl-термом. Чтобы этого избежать, вес у kl части 
ошибки следует прибавлять по какой-нибудь гладкой функции от $0$ до $1$ 
(Рис.~\ref{kl_term_w}). Мы также хотим немного подпортить жизнь декодеру, 
применяя вместо обычного новый "word dropout" - в процессе обучения случайно 
заменяем последнее слово на $\unk$.

\begin{figure}[h]
\centering
\includegraphics[width=0.85\textwidth]{images/kl_term_w.png}
\caption{Изменение веса kl-терма в процессе обучения}
\label{kl_term_w}
\end{figure}

Теперь TextVAE можно успешно обучить, получив интересные интерпретируемые 
свойства. Семантический смысле, относительно латентного 
пространства, начинает плавно перетекать от предложения к предложению. Чтобы 
заметить это, давайте возьмем две точки в латентном пространстве и начнем 
декодировать $z$ на пути от одной до другой. Видно, что для AE 
(\ref{ae_path}) переход не плавный, а для VAE (\ref{vae_path}) любые два соседа
на пути семантически близки.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{images/ae_path.png}
\caption{Декодированный путь между точками в латентном пространстве для AE}
\label{ae_path}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{images/vae_path.png}
\caption{Декодированный путь между точками в латентном пространстве для VAE}
\label{vae_path}
\end{figure}

Оригинальная модель VAE не подходит для набора данных с частичной разметкой, а 
также не поддерживает условную генерацию. Расширение для таких задач было 
предложено Hu et al.~\cite{text_cvae}. Архитектура изображена на 
Рисунке~\ref{cvae}. К латентному пространству добавился независимый код $c$,
отвечающий за контролируемое свойство в данных. Декодер разделился на генератор 
и дискриминатор, отвечающий соответствие свойств и данных. Фактически, 
дискриминатор это классификатор в случае категориального свойства и регрессор в
случае непрерывного. Мы больше не сможем оптимизировать всю модель, задав общую
ошибку, из-за того, что дискриминатор принимает дискретное $x$, полученное от
генератора. Процесс оптимизации происходит итеративно в цикле: сначала мы 
делаем шаг по весам дискриминатор, а потом шаг по весам VAE (энкодер + 
генератор). Для того, чтобы избежать проблемы расхождения в качестве генератора
и дискриминатора, на вход для оптимизации последнему подается также 
"soft sample" - этакое матожидание для сэмпла генератора без необходимости
реально сэмплировать из дискретного распределения, а значит без потери свойства
непрерывности и возможности посчитать градиент.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{images/cvae.png}
\caption{Архитектура Conditional TextVAE}
\label{cvae}
\end{figure}

В общем и целом, Conditional TextVAE удолетворяет всем вышеперечисленным 
требованиям. Во-первых, нам не обязательно иметь разметку свойств на всех 
данных: при отсутствие $c$ мы можем просэмплировать его из априорного $p(c)$ в
процессе оптимизации. Во-вторых, количество свойств не ограничено одним: на 
каждый тип $c$ мы можем тренировать свой дискриминатор. В-третьих, теперь мы
можем полностью контролировать процесс генерации, задав нужные $c$ (или взяв
их из априорных) и передав генератору. Тесты показывают, что Conditional TextVAE
требуется совсем немного примеров, чтобы эффективно параметризовать генерацию
управляемыми свойствами (\cite{text_cvae}). Проблемы TextVAE это медленная
оптимизация и ограничения в длине генерируемого сэмпла. Авторы оригинальной 
статьи ограничились длинной в $15$ слов, теряя связность при генерации более
длинных $x$.

\subsection{GAN}
Класс моделей, показывающих лучшие результаты в задачах генерации - генеративные
конкурирующие сети (generative adversarial networks, GAN). В этой части, мы 
кратко рассмотрим принцип работы и расширения для генерации дискретных значений.

\subsubsection{Обзор}
Основная идея GAN'ов~\cite{1406.2661} - переформулировка задачи в терминах 
игры с нулевой суммой между двумя сетками-игроками, генератором и 
дискриминатором. Генератор отвечает за непосредственно низкую по стоимости 
генерацию новых примеров по распределению $\pmodel$, принимая на вход случайных 
шум. Дискриминатор же - это классификатор, пытающийся по $x$ определить, при 
пришел ли он из $\pmodel$ или $\pdata$. Генератор обучается, чтобы обманывать 
дискриминатор, а дискриминатор, наоборот, не давать генератору обмануть себя. 
Процесс показан на Рисунке~\ref{gan_fw}.

\begin{figure}[h]
\centering
\includegraphics[width=0.5\textwidth]{images/gan_fw.png}
\caption{Архитектура GAN}
\label{gan_fw}
\end{figure}

Два игрока представлены двумя нейронными сетками, каждая из которых 
дифференцируема по входным аргументам и по своим весам. Дискриминатор принимает
на вход $x$ и параметризовано $\theta^{(D)}$. Генератор принимает на вход 
латентный вектор $z$, просэмплированный из стандартного нормального 
распределения, и параметризован $\theta^{(G)}$. Каждый из игроков имеет свою
функцию ошибки, которая зависит от аргументов - весов собственной сетки. Так как
каждый из игроков не имеет доступа к параметрам другого и может изменять 
собственное поведение с помощью своих параметров, сценарий более 
естественно определить как игру, нежели как задачу оптимизации. Решение такой
игры - это равновесия Нэша - набор из $\theta^{(D)}$ и $\theta^{(G)}$, так что
каждая из функций находится в локальном минимуме по своим весам.

Тренировочный процесс в GAN'ах это процесс из одновременных стохастических 
градиентных спусков. На каждом шаге, мы сэмплируем два батча данных: один из
тренировочной выборки $x \sim \pdata$, один из генератора $x \sim \pmodel$, 
далее, мы делаем два шага оптимизации: один по весам $\theta^{(D)}$, другой 
по весам $\theta^{(G)}$. Некоторые работы советуют делать разное количество 
шагов у генератора и дискриминатора, но большинство придерживаются правилу "один
шаг на каждого игрока". Оптимизационная игра может быть выражена через 
Формулу~\ref{gan_opt}.

\begin{equation}
\label{gan_opt}
\min_G \max_D V(D, G) = \mathbb{E}_{x \sim \pdata}{[\log{D(x)}]}
+ \mathbb{E}_{z \sim p(z)}{[\log(1 - D(G(z)))]}
\end{equation}

GAN - неявная вероятностная модель. Нигде в архитектуре GAN'ов мы не сможем 
получить явный доступ к $\pmodel$, но зато, вместо этого, мы получаем 
универсальный дешевый генератор сэмплов $x \sim \pmodel$, так что $x$ со 
временем становится неотличимым от реальных примеров, тем самым приближая 
$\pmodel$ к $\pdata$.

\subsubsection{Дискретные данные}
Тонкое место GAN'ов для дискретных значений - вторая компонента в 
Формуле~\ref{gan_opt}. А именно, нам надо уметь пробросить градиент через 
$D(G(z))$ по весам генератора. Это значит, что генератор не может производить
дискретных данных. Устранение такого ограничения - важное направление в GAN'ах
в частности и в генеративных моделях в целом. 
Следуя Goodfellow et al.~\cite{1701.00160}, есть как мимимум 3 очевидных пути
обойти эту проблему:
\begin{itemize}
    \item Алгоритм REINFORNCE (\cite{reinforce}) из обучения с подкрепрением
    \item Методы сэмплирования из дискретного распределения, через которые можно
    пробросить производную (\cite{1611.00712}, \cite{1611.01144})
    \item Переход в непрерывное пространство, подразумевающее возможность 
    обратного декодирования (то есть, предсказываем вектор, а по ниму нужное
    слово)
\end{itemize}

Эти подходы нашли свои отражения в конкретных реализациях 
(\cite{seqgan}, \cite{leakgan}, \cite{gsgan}). Как будет показано далее, все 
они обладают фундаментальной проблемой с разнообразием генерируемых сэмплов, 
что, вероятно, связано с проблемой "mode collapsing"'а 
(\cite{mode_collapsing}). Для тестирования использовались реализации с открытым 
исходным кодом, найденные в Интернете.

\section{Решение}
В данной главе будут описаны используемые данные, удачные подходы, 
которые дали ощутимый прирост в качестве работы, и трудности, с которыми 
пришлось столкнуться в процессе реализации.

\subsection{Данные}
Данная задача подразумевает некоторые ограничения на используемый набор данных.
Для тестирования работоспособности тех или иных подходов, нам потребуются 
текстовые данные, каждый сэмпл которых представляет из себя цельный отрывок
длинной в пару предложений. Одна из основных задач - преодоления ограничения в 
15 слов, поставленное Hu \cite{text_cvae} при тестировании ConditionalVAE. Мы же
условимся расширить длину в два раза, до 30 слов. Для простоты, мы возьмем
возьмем категориальное бинарное свойство окраски текста. Чтобы увеличить
датасет, мы также не будем требовать полной разметки (конкретно для наших 
данных это не играет большой роли, но в общем случае такое предположение 
бывает крайне полезно).

Для размеченной части хорошо подходит Стэнфордский датасет (SST) для анализа 
эмоциональной окраски, основанный на базе данных отзывов о фильмах~\cite{sst}.
Чтобы сохранить область и форму данных, неразмеченная часть также была взята
из отзывов фильмов, но уже из набора данных IMDB~\cite{imdb}. Также, мы считали 
примерами без разметки часть данных SST, которая имела нейтральную окраску. 
Итого, мы получаем около 30000 сэмплов для обучения и по 3000 для валидации и 
тестирования. Для полного сравнения со статьей Hu, мы также протестируем работу
для данных только из SST, а также будем использовать похожий подход для 
тестирования классификатора.

Сырые входные данные также нуждаются в предобработке. Для токенизации, лучше 
всего при тестировании показал себя BPE encoding~\cite{wiki:bpe}. Его 
преимущество также в том, что он никак не зависит от языка, поэтому данное 
решение будет подходить и для других языков. Следуя примерам других 
статей~\cite{text_vae}, мы ограничимся наперед заданным ограничением на размер 
словаря - 15000. Это также необходимо, чтобы избежать резкого увеличения 
количества весов при полносвязном слое перед софтмакс активацией (как несложно 
понять, здесь наблюдается квадратичный рост). Словарь будут также дополнять 4 
служебных слова - $\bos$, $\eos$, $\unk$ и $\pad$ - символы начала и конца, 
обрамляющие любой входной пример, а также символ пустоты при отступе и 
отсутствующего слова.

Для обучения, мы будем объединять примеры в батч, фиксированного размера. 
Естественным образом, разные примеры имеют разную длину, поэтому недостающие
элементы заполняются символом $\pad$. Здесь мы также применим одну и популярных 
оптимизаций - объединять примеры в батч можно примерно одинакового размера, 
тогда и не придется заполнять половину всего тезнора условным символом, так как 
длина всего батча равна максимальной длине примеров в нем.

Мы не делаем никаких строгих предположениях о природе данных, кроме структуры из
последовательности дискретных значений. Таким образом, в дальнейшей работе 
построенная модель может быть использована для генерации сэмплов, пришедших из
другой области.

\subsection{Подходы}
Далее будут описаны лучшие подходы и тонкости реализации, которые в итоге дали
наибольший прирост в эффективности.

\subsubsection{Реализация}
За основу будущей модели было взято описание ContitionalVAE от 
Hu~\cite{text_cvae}. Во-первых, такая модель эффективно умеет работать в 
условия данных с неполной разметкой. Во-вторых, она предоставляет механизм
условной генерации дискретных значений, позволяя явно задавать необходимые 
свойства. В-третьих, в самой статьи описаны удачные подходы для успешного 
обучения.

Модель была реализована на фреймворке PyTorch 0.4~\cite{pytorch} (для 
красивого, расширяемого и поддерживаемого кода). Код доступен в открытом 
репозитории~\cite{github}. При реализации особое внимание уделялось скорости 
обучения и генерации, так как это узкий момент в терминах скорости в 
оригинальном алгоритме. Дело в том, что во время одной итерации
нужно уметь сэмплировать два разных батча из $x$ для прогона одного шага 
оптимизации. Так как сэмплирование происходит слово за словом, любая сложная 
логика на декодере оборачивается проседанием производительности в несколько раз
.

В качестве дискриминатора из оригинальной статьи была взята простая сетка без
нелинейных слоев, не учитывающая $N$-граммы. Такая модель показала низкий 
прирост качества классификации после обучения и не способна правильно 
классифицировать сложные длинные куски текста, в которых не раз может меняться
направление мысли, тон, настроение и эмоциональная окраска в целом.
Дискриминатор из оригинальной статьи был переписан на 
CNNEncoder~\cite{1510.03820}, представляющий из себя комбинацию из нескольких 
сверточных слоев, связанными max-pooling'ом и нелинейными активациями (SELU). 
Такая модель также учитывает 2-3-4-5-граммы слов, показывая хороших результаты 
на бинарной классификации предложений. Один из очевидных плюсов такого 
дискриминатора - отсутствие полносвязных и рекуррентных слоев, из-за которых 
скорость обучения заметно падает.

В качестве эмбеддингов (векторизации) для слов был взят набор предобученных
векторов GLoVE размерностью $100$. Веса не замораживались во время обучения,
так как, фактически, мы брали данные из конкретной области - отзывов о фильмах,
поэтому и контекст использования может слегка сместиться. В то же время, данных
для обучения было достаточно, чтобы не потерять способность к обобщению.

Авторы оригинальной Text VAE~\cite{text_vae} использовали несколько трюков, 
позволяющих эффективней обучить модель на текстовых данных, которые также были 
применены и здесь. Во-первых, помимо обычного рекуррентного 
дропаута~\cite{wiki:dropout} между слоями и шагами в RNN, был применен 
WordDropout - небольшой расширение, позволяющее реже смотреть на последнее 
слово при выводе и генерации. Это легко обобщается до KWordDropout - аннулируем
$k$ последних слов с вероятностью, распределенной по убывающей от конца 
функцией. Интуиция тут примерно следующая: чем длиннее текст, тем вероятнее 
последнее словосочетание, а не единичное слово повлияют на выбор следующего. 
Вероятность для дропаута была взята со значением $0.3$, повторяя выбор 
оригинальной статьи. Во-вторых, вес переменный kl-терма был заменен с 
линейного роста на рост по гладкой $\tanh$, переведенной в $[0, 1]$. Это 
позволило немного уменьшить ошибку на kl-части, введя более гладкий переход 
при регуляризации.

Следуя Howard из fast.ai~\cite{fastai}, мы использовали метод обучения 
SGDR~\cite{1608.03983}, основанный на Adam с $3$ рестартами. Мы обрезали 
градиент, для предотвращения взрывов на начальной стадии обучения со значением
$10$. Скорость обучения бралась традиционна маленькой для подобных задач, 
изменявшись в цикле с $1e-2$ до $1e-3$. Размер батча - $64$. Все обучение, как 
и генерация, происходило на графическом процессоре GeForce GTX $1080$, что
заметно ускоряло процесс подгона параметров.

Таким образом, большинство значений подобрано эмпирически на валидации или 
взято из оригинальной статьи, а некоторые вещи удалось видоизменить или 
обобщить для большей устойчивости к длине генерации.

\subsubsection{SRU}
Как уже было сказано выше, для повышения скорости обучения и сэмплирования 
важно иметь быстрые энкодер и генераторы. Одна итерация в цикле оптимизации, 
эквивалентному Wake-Sleep алгоритму~\cite{text_cvae}, требует сэмплирования 2ух
батчей данных $x$, один из которых параметризован конкретным свойством $c$.
Процесс генерации - самый трудозатратный во всем алгоритме, во многом из-за
реализации его в виде алгоритма Beam Search, требующего поддержания $k$ 
кандидатов на каждый пример из батча. Наивная реализация показала, что 
одна полная оптимизация модели может занимать десятки часов, что 
катастрофически много для тестирования, подгона параметров и архитектурных 
выборов. Итак, решено было ускорить процесс за счет двух оптимизация: замены 
RNN на CNN и переписывании алгоритма генерации в виде векторных операций на 
графическом процессоре.

SRU~\cite{1709.02755} - идеологически, рекуррентная нейронная сеть, в которой 
матричные операции внутри очередного шага заменены на сверточные нейронные 
сети. Для использования в данной модели была заимствовано, доделана и 
изменена референсная реализация SRU. Такая вариация RNN позволяет минимум 
вдвое сократить время на обучение, вдвое же увеличив количество слоев. 
Результаты показывают, что $6$-слойные SRU при долгой оптимизации и дропаутом 
могут даже увеличить результаты в метрики терминах $Perplexity$. Таким 
образом, замена RNN-ок в энкодере и генераторе на SRU даст ощутимый прирост в 
скорости и эффективности. Однако, следует учесть, что обучение генератора с 
SRU теряется информативность скрытых векторов, поэтому строить Attention, 
основываясь на их связи, не получается. Attention играет важную роль в 
построение интерпретируемой модели с увеличенной длинной генерации, поэтому 
решено было реализовать $3$-слойный SRU без дропаута (чтобы помочь энкодеру, 
особенно на начальном этапе) в качестве энкодера, и $2$-слойный GRU с 
дропаутом в $0.3$ в качестве генератора.

Суммарно, обе оптимизации дали почти шестикратный прирост в скорости,
что позволило сократить до часа с небольшим процесс обучения до сходимости.

\subsubsection{Стохастический Beam Search}
Выше, уже было сказано о дихотомии двух подходов к генерации. С одной стороны,
мы можем всякий раз сэмплировать очередное новое слово и двигаться дальше. С
другой стороны, мы можем детерминировано выбирать $\argmax$. Оба подхода 
обладают рядом недостатков: с одной стороны мы заботимся о разнообразии, с 
другой - о высокой совместной вероятности у кандидатов, т.е. правдоподобии.
Более того, случай с $\argmax$ - вырожденный, мы всегда будем ровно один
уникальный сэмпл при генерации. Необходимо придумать компромисс, с помощью 
которого можно эффективно получать длинные сэмплы.

Интуитивно, мы хотим просэмплировать префикс, задав основную часть выражения и 
добрать суффикс $\argmax$'ом. Вариация алгоритма beam search, которая позволяет
найти удачный компромисс для двух подходов, приблизив нас к интуиции - 
стохастический beam search~\cite{sbeamsearch}. Мы также поддерживаем $k$ 
кандидатов, но новых выбираем не через максимизацию, а через честное 
сэмплирование. Параметр $k$, подбираемый на валидации, позволяет эффективно 
найти нечто среднее между двумя крайними случаями. Помимо этого, алгоритм 
также параметризуется температурой софтмакс-активации, чтобы напрямую 
контролировать разнообразие. Итого, получаем гибкий алгоритм с реализацией в 
векторных операциях на графическом процессоре, через который можно выразить в
се остальные подходы, контролируя $k$ и температуру $\tau$. Например, greedy 
decoding выражается через $k=1$ и $\tau=\epsilon > 0$ (распределение стремится 
к one-hot). Параметр, подобранный при запусках: $k=3$, $\tau=1$ не изменялось 
во время обучения, но её увеличение дает эффективный способ повышения 
разнообразия.

\subsubsection{Self-Attention}
Основной механизм увеличения длинны генерации в стандартных seq2seq моделях
для машинного перевода - использования механизма внимания (attention). 
Фактически, на каждом шаге мы добавляем информацию о коррелируемости всех 
предыдущих шагов с энкодера, что позволяет учитывать даже long-term 
зависимости между словами в предложении. Такое расширение не только позволяет
сохранять связность, но и добавляет модели интерпретируемости: теперь мы можем
нарисовать матрицу внимания, которая покажет зависимости слов от контекста до 
них (Рис.~\ref{attention}). Такая матрица внимания существует для каждого 
кандидата при генерации.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{images/attention.png}
\caption{Матрица внимания}
\label{attention}
\end{figure}

Проблема с генеративными моделями заключается, однако, в отсутствии энкодера 
(точнее, отсутствии доступа к нему во время генерации). Мы предлагаем 
расширение механизма внимания на генеративные модели: механизм 
самовнимания (self-attention). Похожие по идеологии подходы стали популярны в 
совсем недавних статьях, поэтому и предложено схожее 
название~\cite{1706.03762}, \cite{1805.08318}. Фактически, мы используем 
информацию с предыдущих шагов декодера, добавляя ее на очередном шаге при 
выводе (Рис.~\ref{self_attention}). Важный момент - как считать матрицу 
внимания, чтобы правильно учесть последнее слово. Для этого, при определении 
коррелируемости использовались новый $o'_i$, представляющий сбор информации с 
предыдущих шагов, и старые $o_i$. Для реализации 
была выбрана вариация общего (general) внимания с полносвязными слоями до и 
после сбора векторов контекста с SELU-активацией после. Реализация была 
выполнена в виде отдельной сетки-модуля для PyTorch, поэтому также может быть
использована в других моделях и задачах.

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{images/self_attention.png}
\caption{Архитектура Self-Attention}
\label{self_attention}
\end{figure}

Важное преимущество, которое мы получили, реализовав данный механизм - резкое
повышение интерпретируемости (Рис.~\ref{sa_sample1}, \ref{sa_sample2}). На 
графиках изображены матрица внимания собранные при генерации конкретных сэмплов
. В генерации, мы движемся по оси $x$ слева направо и не можем смотреть в 
будущее, поэтому все веса находятся ниже транспонированной главной диагонали. 
Теперь явным образом наблюдаются не только зависимости одних слов и выражений 
от других, но и разнообразные вырожденные случаи (хотя они и будут видны 
невооруженным глазом в виде повторяющего партерна на матрице, они позволяют 
обратить внимание на возможные проблемы в реализации и обучении). В общем и 
целом, такой механизм не только дал наибольший прирост на метриках, но и 
значительно расширил представление о том, как именно нейросеть генерирует
очередной сэмпл.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{images/sa_sample1.png}
\caption{Матрица Self-Attention для конкретного кандидата 1}
\label{sa_sample1}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{images/sa_sample2.png}
\caption{Матрица Self-Attention для конкретного кандидата 2}
\label{sa_sample2}
\end{figure}

\subsubsection{Штраф за покрытие на матрице внимания}
Еще один большой плюс матрицы внимания - возможность ввести регуляризацию на
кандидатов. Одной из самых больших проблем генерации является ранжирование 
кандидатов при beam search. Стандартный подход - ранжирование по логарифму 
совместной вероятности, т.е. произведению всех вероятностей на пути в BM дереве
. Однако, как несложно понять, в таком случае более короткие примеры будут 
иметь больший шанс быть выбранными, просто потому что они заканчиваются 
раньше, и не имеют добавки в виде префикса-вероятности, снижающем общую 
вероятность кандидата. 

Есть несколько способов избежать этого. Можно нормализовать вероятность по 
длине, можно добавить к очкам кандидата регуляризацию по длине 
$\beta \cdot |x|$. Однако, они плохо обощаются на вырожденные случаи с 
повторяемыми кусами текста. Следуя~\cite{1703.03906}, мы предлагаем подход в 
виде штрафа на матрице self-attention (Формула~\ref{coverage_penalty}). Такой
штраф добавляем к логарифму совместной вероятности для учета в итоговом 
ранжировании. Интуитивно, чем более заполнена матрица и чем более она 
соответствует случаю "каждое слово раздает единицу внимания всем другим", тем
лучше. Такой подход позволил практически полностью избежать вырожденных случаев
при генерации (слишком коротких, повторяющихся, незаконченных), увеличив 
итоговые метрики.

\begin{equation}
\label{coverage_penalty}
cp(A) = \sum\limits^{|x|}_{i=1}{\log \left[\min(\sum\limits^{|x|}_{j=1}{A_{ij}}, 1) \right]}
\end{equation}

\section{Оценивание}
В этой главе мы рассмотрим способы оценки алгоритмов генерации, а 
также обсудим как правильно представить и сравнить результат работы 
генеративных моделей.

\subsection{Метрики}
Лучший и самый надежный способ оценить качество генерации - автоматические 
метрики и воспроизводимое окружение. К сожалению, большинство стандартных метрик
обладает большим количеством недостатков. Они могут либо плохо коррелировать
с человеческим восприятием, либо требовать непомерно много вычислительных 
ресурсов, а также быть зависимыми от конкретного приложения. Поэтому, все еще остра
необходимость в метрике для генеративных задач, которую можно было бы 
использовать в любом окружении, не затрачивая много времени и средств.
\cite{book:salp}.

\subsubsection{BLEU}
BLEU~\cite{bleu} это алгоритм для оценки качества машинного перевода из одного естественного
языка на другой. Основная идея BLEU - чем ближе машинный перевод к эталонному
человеческому, тем лучше. BLEU до сих пор остается самой популярной и низкой
по стоимости метрикой, использующуюся повсеместно в задачах генерации текста.

Несмотря на свои недостатки~\cite{bleu_critique}, BLEU позиционируется как 
метрика имеющая высокую корреляцию с человеческим пониманием качества. По 
крайней мере, до сих пор не было предложено метрики, превосходящей BLEU по 
качеству оценки перевода. В последнее время, принимаются попытки расширить 
определение BLEU или даже переделать алгоритм в набор дифференцируемых
преобразований, так, чтобы метрику напрямую можно было бы оптимизировать в 
процессе обучения, но такие подходы до сих пор не пользуются большой 
популярностью.

BLEU используется как метрика, оценивающая качество перевода целого корпуса 
текста и теряет значимость, если с помощью нее пытаются оценить одно или
несколько предложений. BLEU - это число в промежутке от $0$ до $1$. BLEU для 
одного примера считается по кандидатам, которых выдала модель и нескольким
эталонным вариантам перевода (одна и та же фразу может иметь несколько 
популярных или общепринятых способов быть переведенной). Варианты перевода 
получаются, если модели присваивает большую вероятность сразу нескольким кандидатам. 
Эталонные варианты обычно получаются от разных профессиональных переводчиков, чтобы 
результаты были декоррелированы и система оценки была более устойчивой 
(Рис.~\ref{bleu_example}). Это также позволяет эффективно бороться с проблемой
полноты в оценке.

\begin{figure}
\centering
\includegraphics[width=0.6\textwidth]{images/bleu_example.png}
\caption{Пример для подсчета BLEU}
\label{bleu_example}
\end{figure}

BLEU - метрика, основанная на N-грамной схожести предложений. Для кажого $n$
мы считаем точность $p_n$ по формуле \ref{bleu_pn}. $Count(ngram)$ - это 
количество вхождений конкретной $ngram$-мы в всех эталонные примеры. 
$Count_{clip}$ считается по формуле $\ref{bleu_countclip}$. Фактически, $p_n$
показывает точность вхождений $n$-грам из кандидатов в эталоны.

\begin{equation}
\label{bleu_pn}
p_n = \frac{\sum\limits_{C \in \{candidates\}}{\sum\limits_{ngram \in C}{Count_{clip}(ngram)}}}{\sum\limits_{C' \in \{candidates\}}{\sum\limits_{ngram' \in C}{Count(ngram')}}}
\end{equation}

\begin{equation}
\label{bleu_countclip}
Count_{clip}(ngram) = min(Count(ngram), |\{references\}|)
\end{equation}

Далее, для подсчета BLEU мы берем геометрическое среднее $p_n$ с весами, 
суммирующимися до $1$цы, умножая результат на "штраф за длину" 
(brevity penalty, BP). Мы берем $n$-граммы, начиная с униграмм вплоть до $N$, 
где $N$ обычно равняется $4$ или $5$. BP вычисляется по формуле \ref{bleu_bp}. 
$c$ - это сумма длин кандидатов, $r$ - сумма длин ближайший по длине эталонов 
по каждому кандидату (такая логика нужна, чтобы не штрафовать коротких 
кандидатов слишком сильно). Итоговое значение BLEU считается по формуле 
\ref{bleu_final}. Взяв логарифм, получаем удобную к вычислению и последующему
сравнению формулу \ref{bleu_final_log}. Стоит также отметить, что стандартные 
веса в формуле BLEU распределены равномерно, т.е. $w_n = \frac{1}{N}$.

\begin{equation}
\label{bleu_bp}
BP = 
\begin{cases}
1 &\text{if } c > r\\
e^{1 - \frac{r}{c}} &\text{if } c \leqslant r
\end{cases}
\end{equation}

\begin{equation}
\label{bleu_final}
BLEU = BP \cdot exp(\sum^{N}_{i=1}{w_n \log{p_n}})
\end{equation}

\begin{equation}
\label{bleu_final_log}
log BLEU = min(1 - \frac{r}{c}, 0) + \sum^{N}_{i=1}{w_n \log{p_n}}
\end{equation}

\paragraph{BLEU}
Как же использовать метрику из машинного перевода для задач генерации текста? 
Так как BLEU основанная на $n$-граммной схожести предложения, она может подойти
не только для оценки качества перевода, но и для оценки качества генерации: в 
качестве кандидатов теперь будет выступать корпус из сгенерированных примеров, а
в качестве эталонов - набор из валидационного множества, не встречаемого при
обучении.

Такой подход обладает рядом недостатков: недостаточно хорошая корреляция с 
человеческой оценкой, большая дисперсия и невозможность сравнения с другими 
задачами, использующими BLEU как основную метрику (хотя бы потому, что 
максимальное практическое теперь будет гораздо меньше $1$). Тем не менее, есть
и огромное преимущество: мы никак не зависим от окружения, не делаем никаких
предположений о внутренней структуре модели (в отличии от Perplexity),  
низкая стоимость подсчета и отсутствие проблем редкими словами.

Данная метрика будет основной в данной работе и отвечает за правдоподобие 
сгенерированных примеров. Отчасти это связано с невозможность обойти проблемы
Perplexity, отчасти с доступностью сравнений с результатами из других статей.

\paragraph{Self-BLEU}
Заметим, однако, что не всегда большой BLEU свидетельствует от хорошей работе
генеративной модели. Рассмотрим крайний случай: $\pmodel$ является вырожденным
распределением, дающим $100\%$ вероятности одному хорошему примеру. BLEU метрика
высокая, однако результат далек от идеального. Таким образом, помимо 
правдоподобия, нам также необходимо поддерживать разнообразие генерируемых 
примеров. Это одно из важные свойств хорошей генеративной модели, которому
часто не придают большого веса.

Как подсчитать разнообразие примеров? Один из несложных способов - простое 
расширение BLEU, основанное на подсчете метрики на сэмплах с самими собой. 
Следуя описанию похожей метрики, описанной в \cite{1802.01886}, условимся 
называть эту метрику Self-BLEU. Self-BLEU это успредненное BLEU по каждому
из примеров со всеми остальными. Условного ее можно описать формулой 
\ref{self_bleu}.

\begin{equation}
\label{self_bleu}
SELF\_BLEU(S) = \frac{1}{|S|} \sum\limits^{|S|}_{i=1}{BLEU(S_i, S \setminus S_i)}
\end{equation}

Self-BLEU обладает таким же набором недостатков и преимуществ, но гораздо менее
распространен, в следствии чего показания не получится сравнить с другими 
результатами. В отличии от BLEU, нас будут интересовать низкие значения 
Self-BLEU, так как нам интересно более полно моделировать $\pdata$, не 
ограничиваясь небольшим количество хороших сэмплов.

\subsubsection{Perplexity}
Perplexity используется для оценки того, насколько данная последовательность 
вероятна для текущей модели. Мы хотим выдавать большую вероятность предложениям,
имеющий больший смысл и правильную грамматическую структуру. Эта та самая величина,
которая будет отвечать за правдоподобность генерируемых примеров. Perplexity
довольно часть используется в статьях по языком моделям, машинному переводу и 
генеративным моделям, поэтому ее значения удобно соотносить и сравнивать с уже
имеющимися результатами.

Процесс оценки следующий: мы разбиваем данные на тренировочную и тестовую 
выборки, используя для обучения только тренировочную часть. После оцениваем,
насколько вероятны данные из тестовой выборки, усредняя результат по всем 
примерам. Далее, такие оценки могут быть использованы для сравнения различных 
моделей и подходов к генерации \cite{lecture:lm}.

Чтобы посчитать Perplexity используется формула (\ref{perplexity}). Интуитивно,
это величина, обратная совместной вероятности слов в предложении. То есть, 
минимизация Perplexity эквивалентна максимизации совместной вероятности, поэтому
нас будут интересовать понижения значения Perplexity. Совместная вероятность 
удобно раскладывается в последовательное произведение вероятностей слов 
(\ref{perplexity_exp}) по цепному правилу, что может быть использовано в 
дальнейшем.

\begin{equation}
\label{perplexity}
PPL(w) = P(w_1, \cdots, w_{|w|}) ^ {-\frac{1}{|w|}}
\end{equation}

\begin{equation}
\label{perplexity_exp}
P(w_1, \cdots, w_{|w|}) ^ {-\frac{1}{|w|}} = \sqrt[|w|]{\frac{1}{P(w)}} = 
\sqrt[|w|]{\frac{1}{\prod^{|w|}_{i=1}{P(w_i | w_{<i})}}}
\end{equation}

Основная сложность подсчета заключается в оценки совместной вероятности $P(w)$.
Более ранние работы из подходов, основанных на статистике, предлагали оценку, 
основанную на N-грамных методах (\ref{perplexity_ngram}). Такой подход, помимо
прочих недостатков, требует большое количество времени на подсчет количества 
N-грам $Count(w)$ с ростом $N$, являясь при этом приближенным значением 
(Рис.~{\ref{ngram_comp}}). Поэтому, такой подход к оцениванию вероятности не
позволит хорошо оценить эффективность модели.

\begin{equation}
\label{perplexity_ngram}
P(w_i | w_{<i}) \approx P(w_i | w_{<i-N+1}) 
\approx \frac{Count(w_i, \cdots, w_{i-N+1})}{Count(w_{i-1}, \cdots, w_{i-N+1})}
\end{equation}

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{images/ngram_comp.png}
\caption{Сравнение Perplexity для N-грамных методов}
\label{ngram_comp}
\end{figure}

Заметим, однако, что для совместной вероятности нам всего лишь нужно уметь 
считать вероятность следующего слово по контексту-префиксу из предшествующих 
ему. Явный доступ с такому распределению позволяют получить модели с 
генератором рекуррентной нейронной сетью, то есть большинство из показывающих
лучшие результаты на данный момент, в том числе VAE и GAN. На очередном шаге
rnn-ки мы можем после оценить вероятность следующего слова, выбрав в нужную
вероятность после Softmax активации.

Сложность, возникающая в процессе подсчета Perplexity состоит в том, что 
некоторые части предложения, оцениваемые моделью, склонные получать очень 
низкую вероятность, ввиду своей нечастой встречаемости или отсутствия в 
словаре, построенном на тренировочном множестве. Примером могут послужить редкие 
имена собственные или стилистические особенности. В результате, Perplexity, 
подсчитанная на таких примерах, стремится в $\infty$, переставая быть 
репрезентативным значением. Так как нам интересна эффективность работы "в 
среднем", без рассмотрения частных случаем с редкими словами, мы заменяем 
такие плохие значения Perplexity константным большим числом (конкретное 
значение варьируется и зависит от задачи). Эксперименты показали, что количество
плохих Perplexity со значением $\infty$ очень мало, поэтому такая замена 
позволяет сохранить значимость метрики без рассмотрения частных особых случаев.

Итак, Perplexity представляет из себя очень эффективную, быструю и низкую по
стоимости метрику, повсеместно использующуюся с задачах генерации.

\subsubsection{Человеческая оценка}
Пожалуй, лучший способ оценить качество генеративных моделей - мнение человека.
В отличии от других задача машинного обучения, в задачах генерации, мнение и 
способности человека - абсолют. Нам не зачем создавать новые экземпляры текста, 
если они не могут быть правильно проинтерпретированы и поняты человеком. 
Поэтому, человеческое восприятие - важный компонент в задачах генерации. 
Проблемы такого подхода - контекст (культурный, социальный, исторический), из-за
чего разные группы людей могут оценивать разные сэмплы по-разному и большая
стоимость оценки (с точки зрения ресурсов и времени).

Частично, справиться с последней проблемой помогают набирающие популярность сервисы
, позволяющие размещать в Интернета задания, в том числе и задания по разметке
данных и оценке тех или иных данные по различным критериям, такие как 
\cite{yatoloka} и \cite{mturk}. Все же, такие сервисы подходят скорее для 
промышленных задач, чем для научной работы, требуя значительных средств для 
хорошего качества. Так или иначе, чтобы получить сносное качество, нам 
понадобится выдавать одно и тоже задание на разметку разным людям, усредняя
общий результат, поэтому окупаемость такого подхода требует подробного 
рассмотрения.

Подходы с человеческой оценкой качества - частый способ оценки в задачах 
информационного поиска, но их также применяют и в задачах генерации 
(Salimans et al.\cite{1606.03498}). В данной работе человеческая оценка 
использовалась разве что в качестве "sanity check" (вырожденный результат 
виден невооруженным взглядом), ввиду недостатка ресурсов и большого времени на 
оценку. Тем не менее, такой подход может быть использован в дальнейшем.

\subsection{Результаты}
Опишем основные результаты и краткие выводы, которые удалось получить в ходе 
работы. За базовую модель, основанную на принципе максимального правдоподобия 
(MLE) была взять обычная рекуррентная нейронная сеть, основанная на LSTM. Для 
тестирования на BLEU метриках будем использовать множества из 
$|X_{\texttt{gen}}|=500$ сэмплов. Столь высокие показатели BLEU метрик 
обусловлены в том числе и тем, что в генерируемого множестве часто попадаются 
одинаковые или почти одинаковые сэмплы, которые сопоставляются при подсчете 
$n$-грамм.

Для подходов, основанных на генеративных состязательный сетях, были 
использованы референсные реализации с открытым исходным кодом. GAN'ы обладают 
целым набором проблем при обучении, начиная от правильного сэмплирования 
латентного вектора для генератора, заканчивая расхождением в скорости обучения 
генератора и дискриминатора. Подходы, основанные на алгоритме 
REINFORCE (SeqGAN, LeakGAN), сходятся крайне медленно (до нескольких дней) 
из-за проблем с дисперсией, а некоторые реализации не заботились о 
воспроизводимости вычислений, поэтому запустить их было проблематично. 
Результаты сравнения с $MLE$ представлены на Таблице~\ref{ganmle_table}.

\begin{table}
\begin{tabular}{c | c c c c c c}
\toprule
Metrics & SeqGAN & MaliGAN & RankGAN & LeakGAN & TextGAN & MLE \\
\midrule
BLEU & 18.0 & 15.9 & 15.6 & \textbf{23.0} & 20.7 & 18.9 \\
Self-BLEU & 48.9 & 43.7 & 61.8 & 78.0 & 74.6 & \textbf{40.8} \\
\bottomrule
\end{tabular}
\caption{BLEU5 * 100 для 500 сгенерированных сэмплов}
\label{ganmle_table}
\end{table}

Видно, что несмотря на высокие показатели $BLUE$, все GAN'ы проигрывают 
обычному принципу максимального правдоподобия в разнообразии. Фактически, это
означает, что GAN'ы могут выдавать несколько хороших примеров, но не способны
поддерживать разнообразие генерации. Одна из возможных причин - традиционная 
проблема с правильным сэмплированием внутри алгоритма REINFORCE. Другая 
возможная причина связана с проблемой 
"mode collapsing"a~\cite{mode_collapsing} - краеугольным камнем и главной 
проблемой архитектуры генеративных конкурирующих сетей на данный момент. 
Условно, проблема показана на Рисунке~\ref{ml_vs_gan}. На рисунке изображено 
приближение сложных двумерных данных разными подходами. В то время как MLE 
приближает данные неточно с неким доверительным интервалов, GAN чертит 
вырожденное многообразие без оного, более точно приближающее $x$ в мелких 
масштабах.

\begin{figure}
\centering
\includegraphics[width=\textwidth]{images/ml_vs_gan.png}
\caption{MLE против неявных вероятностных моделей}
\label{ml_vs_gan}
\end{figure}

Одно из заявленные свойств необходимого генератора - поддержание разнообразия, 
которое тут оказалось хуже чем у простой базовой модели. Поэтому, модели 
основанные на GAN'ах в данный момент нуждаются в решении проблемы с 
разнообразием. К слову, похожая проблема наблюдается и в случае непрерывных 
данных. Удачный пример вырожденного генератора, характеризующий общую проблему,
был приведен в~\cite{vetrovgan}.

Результаты для предложенного расширения ConditionalVAE представлены на 
Таблице~\ref{cvae_table}. $BS_k$ - beam search, параметризованный $k$, $CP$ - 
штраф на матрице внимания, $SA$ - self-attention. $D_{ACC}$ - точность на 
классификаторе, $CVAE_{++}$ - CVAE плюс все удачные расширения, дополнения и 
изменения, описанные в главе "Решение".

\begin{table}
\begin{tabular}{c | c c c c}
\toprule
Metrics & VAE & CVAE & $CVAE_{++}$ + SA & \textbf{$\boldsymbol{CVAE_{++}}$ + SA + CP + $\boldsymbol{BS_3}$} \\
\midrule
$D_{ACC}$ & - & 83.483 & \textbf{84.263} & - \\
Perplexity & 150 & 104 & 84 & \textbf{83} \\
BLEU & 6.4 & 9.0 & 18.2 & \textbf{20.5} \\
Self-BLEU & 9.0 & 8.7 & 45.8 & \textbf{44.2} \\
\bottomrule
\end{tabular}
\caption{Метрики для CVAE}
\label{cvae_table}
\end{table}

Видно, что резкий скачок в эффективности происходит при переходе к управляемой
генерации (так мы можем использовать данные с неполной разметкой), а также при
использовании механизма внимания. Стохастический beam search с регуляризацией
также добавляют прирост в метриках, что подтверждает их эффективность. 

Итак, предложенные оптимизации и расширения действительно смогли эффективно 
сохранить высокую правдоподобность и относительно высокое разнообразие, при 
это увеличив длину генерируемых сэмплов вдвое. При этом, мы также эффективно 
расширили модель на условия с данными с частичной разметкой (которые чаще 
всего можно встретить в реальной жизни), сохранив при этом высокую точность 
классификации, а, следовательно, возможность эффективно параметризовать 
генератор требуемыми свойствами.

\section{Заключение}
В этой главе будут представлены итоги, заключение и намечен вектор развития 
дальнейшей работы.

\subsection{Итоги}
В данной работе удалось проанализировать текущие подходы к генерации текста как
последовательности дискретных значений. Были подробно изучены принципы и 
особенности работы генеративных моделей с дискретными значениями, намечены 
основные сложности и проблемы, которые можно встретить при использовании той 
или иной модели.

Основная задача была поставлена, исходя из общей задачи условной генерации 
текста, ориентируясь на несколько конкретных примеров условий для сравнения с
другими подходами и использования в реальном производстве. Основная цель - 
увеличение длины генерируемых сэмплов. Задача была успешно решена. Итоговая 
модель получилась не только эффективной в терминах метрик, но и 
интерпретируемой и гибкой. Свойство интерпретируемости, основанное на 
механизме внимания, не только поможет в дальнейшем правильно анализировать 
влияние того или иного изменения на результат генерации, но и правильно 
подгонят параметры при текущей реализации на новых данных.

Также, намечены основные направления дальнейшей работы, которые не удалось 
осветить и реализовать в текущей постановке задачи.

\subsection{Заключение}
Современное глубокое обучение основано на способности вычислительных графов
быть дифференцируемыми. При переходе к дискретным значениям, старые подходы
перестают работать, поэтому приходиться строить отображения дискретного 
пространства в непрерывное, что так или иначе ведет к проблемам с оптимизацией.
Задача генерации последовательных значений усложняется еще и тем, что 
при увеличении длины входных последовательностей, быстро растет сложность по 
поддержанию связности, правдоподобия и разнообразия генерируемых сэмплов.

Современные генеративные модели все еще обладают рядом фундаментальных проблем,
которые не позволяют считать задачу генерации решенной. Ценность этой работы 
заключается не только в предложенном и описанном подходе, решавшем 
поставленную задачу, но и в трудностях, возникших при реализации и  
тестировании, указывающих на глобальные проблемы и очерчивающих границы 
применимости того или иного метода или модели. Надеемся, что выполненная 
работа станет основой для дальнейшего изучения способности нейросетевых 
архитектур эффективно решать задачу генерации для дискретных данных.

\subsection{Будущая работа}
Первое, на что стоит обратить внимание: преодоление ограничения на выбор 
априорного и апостериорного распределения в моделях, основанных на VAE. Этого 
позволяют добиться модели, вбирающие в себя лучшие свойства VAE и 
GAN~\cite{vetrovgan}, \cite{aae}, \cite{alphagan}. Alpha-GAN также позволяет
эффективно бороться с насущной проблемой mode collapsing'a. Проблема однако в 
том, что на дискретных данные, скорее всего, понадобиться исследовать 
возможность эффективного обучения на дискретных данных.

Можно попытаться проинтерпретировать распределение 
тестовых примеров в латентном пространстве для моделей, основанных на $VAE$. Из
работы~\cite{text_vae} мы знаем, что семантическое значением единицы плавно 
переходит от точки к точке при генерации. Можно проверить, сэмплы с похожими
свойствами группируются, образуя некие большие кластеры. Это повысит 
интерпретируемость при управляемой генерации.

Также, можно попытаться запустить предложенную модель на дискретных не 
строковых данных. Например, на SMILES представлениях молекул, проанализировав 
процент валидных молекулярных структур, а также их разнообразие и получаемые 
свойства.

\bibliographystyle{ugost2008ls}
\bibliography{diploma.bib}

\end{document}
